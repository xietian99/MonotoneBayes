L = 10, tau0_sq = 1e-2)
pkgbuild::compile_dll()
monotoneBayes(X = X, Y = Y, prior = "Regularized HS",
+                      fix = T, c_sq = 1e5, chain = 1, # 10s
monotoneBayes(X = X, Y = Y, prior = "Regularized HS",
fix = T, c_sq = 1e5, chain = 1, # 10s
L = 10, tau0_sq = 1e-2)
devtools::document()
rm(list = c("monotoneBayes"))
devtools::document()
try(roxygen2::roxygenize(load_code = sourceDir), silent = TRUE)
roxygen2::roxygenize()
install.packages("../MonotoneBayes", repos = NULL, type = "source")
library(MonotoneBayes)
stanmodels$RegHSfix
test = monotoneBayes(X = X, Y = Y, prior = "Regularized HS",
fix = T, c_sq = 1e5, chain = 1, # 10s
L = 10, tau0_sq = 1e-2)
install.packages("../MonotoneBayes", repos = NULL, type = "source")
test = monotoneBayes(X = X, Y = Y, prior = "Regularized HS",
fix = T, c_sq = 1e5, chain = 1, # 10s
L = 10, tau0_sq = 1e-2)
library(MonotoneBayes)
test = monotoneBayes(X = X, Y = Y, prior = "Regularized HS",
fix = T, c_sq = 1e5, chain = 1, # 10s
L = 10, tau0_sq = 1e-2)
try(roxygen2::roxygenize(load_code = sourceDir), silent = TRUE)
roxygen2::roxygenize()
library(MonotoneBayes)
library(MonotoneBayes)
library(MonotoneBayes)
test = monotoneBayes(X = X, Y = Y, prior = "Regularized HS",
fix = T, c_sq = 1e5, chain = 1, # 10s
L = 10, tau0_sq = 1e-2)
test = monotoneBayes(X = X, Y = Y, prior = "Regularized HS",
fix = T, c_sq = 1e5, chain = 1, # 10s
L = 10, tau0_sq = 1e-2)
install.packages("../MonotoneBayes", repos = NULL, type = "source")
try(roxygen2::roxygenize(load_code = sourceDir), silent = TRUE)
roxygen2::roxygenize()
try(roxygen2::roxygenize(load_code = sourceDir), silent = TRUE)
roxygen2::roxygenize()
try(roxygen2::roxygenize(load_code = sourceDir), silent = TRUE)
roxygen2::roxygenize()
try(roxygen2::roxygenize(load_code = rstantools_load_code), silent = TRUE)
roxygen2::roxygenize()
roxygen2::roxygenize()
roxygen2::roxygenize()
roxygen2::roxygenize()
roxygen2::roxygenize()
roxygen2::roxygenize()
predictCov = function(model, method = "mean", grid.eq = T, node.t, newX, newZ, returnCI = T){
rs.sampler = rstan::extract(model, pars = c("alpha", "gamma", "Gamma","denominator","cumsum_alphaW"))
L = ncol(rs.sampler$alpha)
M.samples = nrow(rs.sampler$alpha)
if (grid.eq == T){
node.t = seq(0,1, length.out = L + 1)
}
x.J = rowSums(outer(newX, node.t, "-")>=0)
x.J[x.J > L] = L # Extrapolation for new X greater than the maximum X for model fitting
x.J[x.J == 0] = 1  # Extrapolation for new X less than the minimum X for model fitting
y = matrix(rep(newX, each = M.samples), nrow = M.samples, ncol = length(newX))
for (i in 1:length(newX)){
j = x.J[i]
if (j == 1){
y[,i] = ( newX[i] * rs.sampler$alpha[,1] + 1 ) / rs.sampler$denominator
} else {
y[,i] = ( rs.sampler$cumsum_alphaW[,j-1] + (x.N[i]-node.t[j-1]) * rs.sampler$alpha[,j] + 1  ) / rs.sampler$denominator
}
y[,i] = logit(y[,i])
y[,i] = y[,i] + newZ[i] * rs.sampler$Gamma
y[,i] = expit(y[,i])
}
y.mean = colMeans(y)
y.CI = apply(y, 1, quantile,probs = c(0.5, 0.025, 0.975))
y.all <-list("mean" = y.mean, "median" = y.CI[1,],
"l.ci" = y.CI[2,], "u.ci" = y.CI[3,])
return(y.all)
}
roxygen2::roxygenize()
rm(list = c("predictCov"))
roxygen2::roxygenize()
devtools::clean_dll
devtools::clean_dll()
pkgbuild::compile_dll()
roxygen2::roxygenize()
monotoneBayes = function(X, Y, Z, L = 10, tau0_sq = 1e-2, nodes = seq(0,1,length.out = 10+1), Eq.Space = T,
c_sq = 10^2, fix = F,
c_alpha = 1, c_beta = 1 * 200, prior = "Regularized HS", ...){
N = length(Y)
if (Eq.Space == F) {
#nodes = (nodes - min(X))/(max(X) - min(X))
#X = (X - min(X))/(max(X) - min(X))
data.J = rowSums(outer(X, nodes, "-")>=0)
data.J[data.J>=L] = L
data.W = nodes[2:(L+1)]- nodes[1:L]
} else {
nodes = seq(0, 1, length.out = L+1)
#X = (X - min(X))/(max(X) - min(X))
data.J = X %/% (1/L) + 1
data.W = rep(1/L,L)
}
if (is.null(Z)){
dt.stan = list(Y=Y, X = X, J = data.J,  W = data.W, nodes = nodes, L=L, N=N,
local_dof_stan = 1,
global_dof_stan = 1,
tau0_sq = tau0_sq)
if (prior == "Original HS"){
model = rstan::sampling(stanmodels$OrgHS, data = dt.stan, ...)
} else if (prior == "Laplacian"){
model = rstan::sampling(stanmodels$Laplacian, data = dt.stan, ...)
} else if (prior == "Gaussian"){
model = rstan::sampling(stanmodels$Gaussian, data = dt.stan, ...)
} else {
if (fix == T) {
dt.stan$c_sq = c_sq
model = rstan::sampling(stanmodels$RegHSfix, data = dt.stan, ...)
} else {
dt.stan$c_sq_shape = c_alpha
dt.stan$c_sq_scale = c_beta
model = rstan::sampling(stanmodels$RegHS, data = dt.stan, ...)
}
}
} else {
dt.stan = list(Y=Y, X = X, Z=Z, J = data.J,  W = data.W, nodes = nodes, L=L, N=N,
local_dof_stan = 1,
global_dof_stan = 1,
tau0_sq = tau0_sq)
model = rstan::sampling(stanmodels$CovModel_HS, data = dt.stan, ...)
}
return(model)
}
fD.x1 = function(x){
y = x
y[x<=0.4] = 0.2
y[x>0.4 & x<0.7] = x[x>0.4 & x<0.7] * 2 - 0.6
y[x>=0.7]  = 0.8
return(y)
}
logit = function(x){
return(log(x/(1-x)))
}
expit = function(x){
return(exp(x)/(1+exp(x)))
}
fD.x0 = function(x){
y = fD.x1(x)
y = expit(logit(y) - 2)
return(y)
}
x.seq = seq(0,1,length.out = 200)
plot(fD.x1(x.seq), ylim = c(0,1))
plot(fD.x0(x.seq), ylim = c(0,1))
N = 200
data = matrix(0, nrow = N, ncol = 1+1+1+1)
colnames(data) = c("X","Z","trueP","Y")
set.seed(38938)
data[,"X"] = runif(N, 0, 1)
data[,"Z"] = sample(c(0,1), size = N, replace = T)
data[,1] = (data[,1] - min(data[,1])) / (max(data[,1]) - min(data[,1]))
data[which(data[,"Z"]==1),"trueP"] = fD.x1(data[which(data[,"Z"]==1),"X"])
data[which(data[,"Z"]==0),"trueP"] = fD.x0(data[which(data[,"Z"]==0),"X"])
data[,"Y"] = rbinom(N, size = 1, prob = data[,"trueP"])
#data.t = quantile(data$x,  seq(0,1,length.out = L+1))
L = 30
data.t = seq(0,1,length.out = L+1)
data.J = rowSums(outer(data[,"X"], data.t, "-")>=0)
data.J[data.J>=L] = L # change x_max with index L
data.W = data.t[2:(L+1)]-data.t[1:L]
model.hs = monotoneBayes(X = data[,"X"], Y = data[, "Y"],Z = data[,"Z"],
J = data.J,  W = data.W, nodes = data.t, L=L, N=N,
local_dof_stan = 1,
global_dof_stan = 1,
c_sq_shape = 1, c_sq_scale = 1e5,
tau0_sq = 1e-2)
data.J
monotoneBayes = function(X, Y, Z, L = 10, tau0_sq = 1e-2, nodes = seq(0,1,length.out = 10+1), Eq.Space = T,
c_sq = 10^2, fix = F,
c_alpha = 1, c_beta = 1 * 200, prior = "Regularized HS", ...){
N = length(Y)
if (Eq.Space == F) {
#nodes = (nodes - min(X))/(max(X) - min(X))
#X = (X - min(X))/(max(X) - min(X))
data.J = rowSums(outer(X, nodes, "-")>=0)
data.J[data.J>=L] = L
data.W = nodes[2:(L+1)]- nodes[1:L]
} else {
nodes = seq(0, 1, length.out = L+1)
#X = (X - min(X))/(max(X) - min(X))
data.J = X %/% (1/L) + 1
data.J[data.J>=L] = L
data.W = rep(1/L,L)
}
if (is.null(Z)){
dt.stan = list(Y=Y, X = X, J = data.J,  W = data.W, nodes = nodes, L=L, N=N,
local_dof_stan = 1,
global_dof_stan = 1,
tau0_sq = tau0_sq)
if (prior == "Original HS"){
model = rstan::sampling(stanmodels$OrgHS, data = dt.stan, ...)
} else if (prior == "Laplacian"){
model = rstan::sampling(stanmodels$Laplacian, data = dt.stan, ...)
} else if (prior == "Gaussian"){
model = rstan::sampling(stanmodels$Gaussian, data = dt.stan, ...)
} else {
if (fix == T) {
dt.stan$c_sq = c_sq
model = rstan::sampling(stanmodels$RegHSfix, data = dt.stan, ...)
} else {
dt.stan$c_sq_shape = c_alpha
dt.stan$c_sq_scale = c_beta
model = rstan::sampling(stanmodels$RegHS, data = dt.stan, ...)
}
}
} else {
dt.stan = list(Y=Y, X = X, Z=Z, J = data.J,  W = data.W, nodes = nodes, L=L, N=N,
local_dof_stan = 1,
global_dof_stan = 1,
tau0_sq = tau0_sq)
model = rstan::sampling(stanmodels$CovModel_HS, data = dt.stan, ...)
}
return(model)
}
model.hs = monotoneBayes(X = data[,"X"], Y = data[, "Y"],Z = data[,"Z"],
J = data.J,  W = data.W, nodes = data.t, L=L, N=N,
local_dof_stan = 1,
global_dof_stan = 1,
c_sq_shape = 1, c_sq_scale = 1e5,
tau0_sq = 1e-2)
data[,"X"]
Z = data[,"Z"]
Z
pkgbuild::compile_dll()
monotoneBayes = function(X, Y, Z, L = 10, tau0_sq = 1e-2, nodes = seq(0,1,length.out = 10+1), Eq.Space = T,
c_sq = 10^2, fix = F,
c_alpha = 1, c_beta = 1 * 200, prior = "Regularized HS", ...){
N = length(Y)
if (Eq.Space == F) {
#nodes = (nodes - min(X))/(max(X) - min(X))
#X = (X - min(X))/(max(X) - min(X))
data.J = rowSums(outer(X, nodes, "-")>=0)
data.J[data.J>=L] = L
data.W = nodes[2:(L+1)]- nodes[1:L]
} else {
nodes = seq(0, 1, length.out = L+1)
#X = (X - min(X))/(max(X) - min(X))
data.J = X %/% (1/L) + 1
data.J[data.J>=L] = L
data.W = rep(1/L,L)
}
if (is.null(Z)){
dt.stan = list(Y=Y, X = X, J = data.J,  W = data.W, nodes = nodes, L=L, N=N,
local_dof_stan = 1,
global_dof_stan = 1,
tau0_sq = tau0_sq)
if (prior == "Original HS"){
model = rstan::sampling(stanmodels$OrgHS, data = dt.stan, ...)
} else if (prior == "Laplacian"){
model = rstan::sampling(stanmodels$Laplacian, data = dt.stan, ...)
} else if (prior == "Gaussian"){
model = rstan::sampling(stanmodels$Gaussian, data = dt.stan, ...)
} else {
if (fix == T) {
dt.stan$c_sq = c_sq
model = rstan::sampling(stanmodels$RegHSfix, data = dt.stan, ...)
} else {
dt.stan$c_sq_shape = c_alpha
dt.stan$c_sq_scale = c_beta
model = rstan::sampling(stanmodels$RegHS, data = dt.stan, ...)
}
}
} else {
dt.stan = list(Y=Y, X = X, Z=Z, J = data.J,  W = data.W, nodes = nodes, L=L, N=N,
local_dof_stan = 1,
global_dof_stan = 1, c_sq_shape = c_alpha, c_sq_scale = c_beta,
tau0_sq = tau0_sq)
model = rstan::sampling(stanmodels$CovModel_HS, data = dt.stan, ...)
}
return(model)
}
model.hs = monotoneBayes(X = data[,"X"], Y = data[, "Y"],Z = data[,"Z"],
J = data.J,  W = data.W, nodes = data.t, L=L, N=N,
local_dof_stan = 1,
global_dof_stan = 1,
c_alpha = 1, c_beta = 1e5,
tau0_sq = 1e-2)
data.t
model.hs = monotoneBayes(X = data[,"X"], Y = data[, "Y"],Z = data[,"Z"],
Eq.Space = T, L=L,
local_dof_stan = 1,
global_dof_stan = 1,
c_alpha = 1, c_beta = 1e3,
tau0_sq = 1e-2)
model.hs = monotoneBayes(X = data[,"X"], Y = data[, "Y"], Z = data[,"Z"],
Eq.Space = T, L=L,
c_alpha = 1, c_beta = 1e3,
tau0_sq = 1e-2)
install.packages("../MonotoneBayes", repos = NULL, type = "source")
outcome.hs = predictCov(model.hs, grid.eq = T, newX = data[,"X"], newZ = data[,"Z"], returnCI = T)
install.packages("../MonotoneBayes", repos = NULL, type = "source")
outcome.hs = predictCov(model.hs, grid.eq = T, newX = data[,"X"], newZ = data[,"Z"], returnCI = T)
install.packages("../MonotoneBayes", repos = NULL, type = "source")
library(MonotoneBayes)
outcome.hs = predictCov(model.hs, grid.eq = T, newX = data[,"X"], newZ = data[,"Z"], returnCI = T)
pkgbuild::compile_dll()
install.packages("../MonotoneBayes", repos = NULL, type = "source")
try(roxygen2::roxygenize(load_code = rstantools_load_code), silent = TRUE)
roxygen2::roxygenize()
install.packages("../MonotoneBayes", repos = NULL, type = "source")
pkgbuild::compile_dll()
roxygen2::roxygenize()
roxygen2::roxygenize()
pkg_build::compile_all()
pkgbuild::compile_dll()
roxygen2::roxygenize()
install.packages("../MonotoneBayes", repos = NULL, type = "source")
install.packages("../MonotoneBayes", repos = NULL, type = "source")
library(brms)
?brms
?brm
2.5^2]
2.5^2
?stan
try(roxygen2::roxygenize(load_code = rstantools_load_code), silent = TRUE)
roxygen2::roxygenize()
roxygen2::roxygenize()
roxygen2::roxygenize()
2178.56 * 0.65
1416+200
1616/0.65
try(roxygen2::roxygenize(load_code = rstantools_load_code), silent = TRUE)
roxygen2::roxygenize()
# Sep 27 - Updated, rerun simulation
##
## This document corresponds to the draft simulation part 1 : Table 2, 3 and Figure 3.
## But we now fix N and N/L; instead previous of N and L.
## We consider N/L. = 2.5 , 5 , 10 and 25
## Then compare different prior choice for alpha's
library(MonotoneBayes)
library(Iso)
library(dplyr)
source("TrueCurves.R")
x.seq = seq(0,1,length.out = 100)
newData = data.frame("x" = x.seq)
fX1 = function(x){
y = 0.75 * x + 0.15
return(y)
}
#y1 = fX1(x.seq)
fX2 = function(x){
y = x
y[x <= 0.5] = 0.15
y[x > 0.5] = 0.9
return(y)
}
#y2 = fX2(x.seq)
fX3 = function(x){
y = x
y[x<=0.4] = 0.15
y[x<=0.6 & x>0.4] = x[x<=0.6 & x>0.4] * 2.25- 0.75
y[x>=0.6 & x <0.7] = 0.6
y[x>=0.7 & x < 0.8] = x[x>=0.7 & x < 0.8] * 3- 1.5
y[x>0.8] = 0.9
return(y)
}
#plot(fX3(x.seq))
fX4 = function(x){
y = 0.5
return(y)
}
#plot(fX4(x.seq))
fX8 = function(x){
y = 1/(exp(2)+1)*exp(3*x -1)
return(y)
}
fX5 = function(x){
a = log(0.07) + x * 10
y = exp(a) / (1+exp(a))
return(y)
}
fX6 = function(x){
a = -7 + x * 10
y = exp(a) / (1+exp(a))
return(y)
}
fX7 = function(x){
y = 0.9* sin(pi/2*x)
return(y)
}
fX9 = function(x){
y = x
y[x<=0.4] = 0.2
y[x>0.4 & x<0.7] = x[x>0.4 & x<0.7] * 2 - 0.6
y[x>=0.7]  = 0.8
return(y)
}
fX.test = function(x){
a = -1.38 + x * 2.24
y = exp(a) / (1+exp(a))
return(y)
}
f.pava = function(data.x, data.y, x.seq){
model = pava(data.y[order(data.x)])
rs = x.seq
for (i in 1:length(x.seq)){
ind = which(x.seq[i] - sort(data.x) <= 0)[1]
if (!is.na(ind)){
rs[i] = model[ind]
}else{ rs[i] = max(model)}
}
return(rs)
}
f.nplr = function(model, x){
model = model@pars
# Check with nplr / predict
y = model$bottom + (model$top - model$bottom) / (1 + 10^(model$scal * ( model$xmid - x)))^model$s
return(y)
}
# .confInt <- function(stdErr, yobs, newy){
#     n <- length(yobs)
#     ybar <- mean(yobs, na.rm = TRUE)
#     t <- qt(.975, n-2)
#     ci <- t*stdErr*sqrt((1+1/n+(newy - ybar)^2/sum((newy - ybar)^2)))
#     lo <- newy - ci
#     hi <- newy + ci
#     return(list(lo = lo, hi = hi))
#   }
pred.nplr = function(model, newData){
yobs = model@y
ybar <- mean(yobs, na.rm = TRUE)
n = length(yobs)
t <- qt(.975, n-2)
stdErr = getStdErr(model)['stdErr']
modelp = model@pars
# Check with nplr / predict
y = modelp$bottom + (modelp$top - modelp$bottom) / (1 + 10^(modelp$scal * ( modelp$xmid - newData)))^modelp$s
ci <- t*stdErr*sqrt((1+1/n+(y - ybar)^2/sum((y - ybar)^2)))
lo <- y - ci
hi <- y + ci
return(list("mean" = y,  "l.ci" = lo, "u.ci" = hi))
}
pred.logistic = function(model, newData){
rs = predict(model, newData, se.fit = T)
rs.log = NULL
rs.log[["mean"]] = plogis(rs$fit) # exp()/(1+exp())
rs.log[["l.ci"]] = plogis(rs$fit - 1.96 * rs$se.fit)
rs.log[["u.ci"]] = plogis(rs$fit + 1.96 * rs$se.fit)
# sapply(rs.log, `[`,2)
return(rs.log)
}
predict.brms = function(model, newData){
rs = brms::posterior_epred(model, newData)
y.mean = colMeans(rs)
y.CI = apply(rs, 2, quantile,probs = c(0.5, 0.025, 0.975))
y.all <-list("mean" = y.mean, "median" = y.CI[1,],
"l.ci" = y.CI[2,], "u.ci" = y.CI[3,])
return(y.all)
}
N =50
distX = "Uniform"
which_outcome  = "fX1"
arrayID = 1
NovL = 2.5
# distX %in% c("Uniform", "Beta")
# which_outcome %in% c("fX1", "fX2", "fX3", "fX4")
# N = 50, maximun 20 min
# N = 500, 30 min
# N = 500
# distX = "Beta"
# which_outcome = "fX1"
# arrayID = 1
# Generate Datasets of Uniform Distribution
set.seed(108)
simSeeds = sample(.Machine$integer.max, 500)
set.seed(simSeeds[arrayID])
data = matrix(0, nrow = N, ncol = 6)
if (distX == "Uniform"){
data[,1] = runif(N, 0, 1)
} else if (distX == "Beta") {
data[,1] = rbeta(N, shape1 = 2, shape2 = 2)
}
minX = min(data[,1]); maxX = max(data[,1])
data[,1] = (data[,1] - minX) / (maxX - minX)
# Apr 10
# Try next time instead of hard coding
data[,2] = rbinom(N, 1, prob = fX1(data[,1]))
data[,3] = rbinom(N, 1, prob = fX2(data[,1]))
data[,4] = rbinom(N, 1, prob = fX9(data[,1]))
data[,5] = rbinom(N, 1, prob = fX5(data[,1]))
data[,6] = rbinom(N, 1, prob = fX7(data[,1]))
colnames(data) = c("x",paste("fX",c(1,2,9,5,7), sep = ""))
data = as.data.frame(data)
N/NovL
50 / 3
L = floor(N/NovL)
nodes.L = quantile(data$x,  seq(0,1,length.out = L))
dt.pred = NULL
basename = c("RHS_fix","RHS_InvG","Laplacian","Gaussian")
basename = c("RHS_fix","RHS_InvG","Laplacian","Gaussian")
TimeNames = c(basename, paste(basename, "eq", sep = "_"))
TimeNames
RunTime = rep(0, length = length(TimeNames))
names(RunTime) = TimeNames
try(roxygen2::roxygenize(load_code = rstantools_load_code), silent = TRUE)
roxygen2::roxygenize()
try(roxygen2::roxygenize(load_code = rstantools_load_code), silent = TRUE)
roxygen2::roxygenize()
install.packages("../MonotoneBayes", repos = NULL, type = "source")
try(roxygen2::roxygenize(load_code = rstantools_load_code), silent = TRUE)
roxygen2::roxygenize()
install.packages("../MonotoneBayes", repos = NULL, type = "source")
install.packages("../MonotoneBayes", repos = NULL, type = "source")
